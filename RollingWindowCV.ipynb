{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series Cross Validation (CV) splits\n",
    "> In this notebook some resources and code implementations to   \n",
    "extend sciki-learn splitting methods for CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Using generators and yelds in Python](https://realpython.com/introduction-to-python-generators/?fbclid=IwAR3MsCOz5lqKm_oOF3F5kmr_y0W2xiBnnZleE9R23aMwtU3CkoOg6tz-wVA)   \n",
    "[time-series cross validation walk-forward](https://medium.com/eatpredlove/time-series-cross-validation-a-walk-forward-approach-in-python-8534dd1db51a)   \n",
    "[Cross validation strategies](https://hub.packtpub.com/cross-validation-strategies-for-time-series-forecasting-tutorial/)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful books:   \n",
    "<div style=\"display: inline-block;text-align: left\" >\n",
    "<a href=\"https://github.com/PacktPublishing/Machine-Learning-for-Algorithmic-Trading-Bots-with-Python\">\n",
    "<img src=\"https://www.packtpub.com/media/catalog/product/cache/e4d64343b1bc593f1c5348fe05efa4a6/v/1/v12962_low.png\" width=\"100px\" style=\"display: block; margin:20px auto;\" >\n",
    "</a>\n",
    "\n",
    "<a href=\"https://github.com/PacktPublishing/Hands-On-Machine-Learning-for-Algorithmic-Trading/tree/master/Chapter10\">\n",
    "<img src=\"https://www.packtpub.com/media/catalog/product/cache/e4d64343b1bc593f1c5348fe05efa4a6/b/1/b11166_new.png\" width=\"100px\"  style=\"display: block; margin:20px auto;\">\n",
    "</a>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    KFold,\n",
    "    cross_validate,\n",
    "    TimeSeriesSplit,\n",
    ")\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV plotting helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, X, y, ax, n_splits, lw=10):  #\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=None)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii] * len(indices),\n",
    "            c=indices,\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "            cmap=plt.cm.coolwarm,\n",
    "            vmin=-0.2,\n",
    "            vmax=1.2,\n",
    "        )\n",
    "\n",
    "    # Formatting\n",
    "    ax.set(\n",
    "        yticks=np.arange(n_splits),\n",
    "        xticks=np.arange(len(indices), 1),\n",
    "        xlabel=\"Sample index\",\n",
    "        ylabel=\"CV iteration\",\n",
    "        ylim=[n_splits, -1],\n",
    "    )  # , xlim=[0, 100])\n",
    "    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple X array to use as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [ 1  4  7 10 13 16 19 22 25 28 31 34 37 40 43 46 49 52 55 58]\n",
      "\n",
      "Number of samples:20\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(1, 60, 3)\n",
    "print(f\"X: {X}\")\n",
    "n_sample = len(X)\n",
    "print(f\"\\nNumber of samples:{n_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocking TimeSeries Split \n",
    "from \"Hands-on Machine Learning for Algorithmic Trading Bots with Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockingTimeSeriesSplit:\n",
    "    def __init__(self, n_splits, waste):\n",
    "        self.n_splits = n_splits\n",
    "        self.waste = waste\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        k_fold_size = n_samples // self.n_splits\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        waste = self.waste  # 32\n",
    "        for i in range(self.n_splits):\n",
    "            start = i * k_fold_size\n",
    "            stop = start + k_fold_size\n",
    "            mid = int(0.8 * (stop - start)) + start\n",
    "            print(\"Start: \" + str(start) + \" \" + str(mid) + \" stop: \" + str(stop))\n",
    "            yield indices[start:mid], indices[mid + waste : stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roll window\n",
    "> A flexible roll window Cross-Validator useful for scenarios like:\n",
    "* A fixed sized train window (rolling) \n",
    "* Everything that is not in training (even at previous time-steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollWindow:\n",
    "    \"\"\" Rolling Window cross-validator\n",
    "    \n",
    "        Provides train/test indices to split data samples\n",
    "        that are observed at fixed time intervals, in train/test sets.\n",
    "        In each split, test indices must be higher than before, \n",
    "        and thus shuffling in cross validator is inappropriate.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_size : int, required\n",
    "            Length of training set.\n",
    "\n",
    "        shift_step : int, required\n",
    "            Number of step to shift training window at each fold.\n",
    "            If equal to training_size the resulting test sets\n",
    "            do not overlap with training, if greater \n",
    "            \n",
    "        horizon: int, optional\n",
    "            Length of test set(forecasting horizon), If not provided\n",
    "            all data till end of dataset is available as test.\n",
    "        \n",
    "        Return\n",
    "        -------\n",
    "        <genarator object> providing tuples of (Train, Test) indexes\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_size, shift_step, horizon=None):\n",
    "        self.train_size = train_size\n",
    "        self.shift_step = shift_step\n",
    "        self.horizon = horizon if not horizon is None else 0\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        # define number of sample\n",
    "        n_samples = len(X)\n",
    "        # create an array of indexes\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        # defint initial start and end for training\n",
    "        startTrain = 0\n",
    "        endTrain = self.train_size\n",
    "\n",
    "        # set iteration condition i.e. iterate while\n",
    "        # trainig window + horizon does not reach the end\n",
    "        # of indexes array\n",
    "        while (indices[-1] - (endTrain + self.horizon)) >= 0:\n",
    "            startTest = endTrain\n",
    "            endTest = startTest + self.horizon\n",
    "            if self.horizon > 0:\n",
    "                indTest = np.hstack([indices[0:startTrain], indices[startTest:endTest]])\n",
    "            else:\n",
    "                # if self.horizon == 0 (not provided) test see extend till the end\n",
    "                indTest = np.hstack([indices[0:startTrain], indices[startTest:]])\n",
    "            # define training indexes\n",
    "            indTrain = indices[startTrain:endTrain]\n",
    "            # yield tuple of training and test indexes\n",
    "            yield indTrain, indTest\n",
    "            # update train indexes for next iteration\n",
    "            startTrain = startTrain + self.shift_step\n",
    "            endTrain = startTrain + self.train_size\n",
    "\n",
    "\n",
    "train_size, period, horizon = 4, 4, None\n",
    "rw = RollWindow(train_size=train_size, shift_step=period, horizon=horizon)\n",
    "print(f\"\\nTrain size:{train_size}, Period:{period}, Horizon:{horizon}\\n\\n\")\n",
    "for i, (tr, tt) in enumerate(rw.split(X)):\n",
    "    # print(f\"Iteration: {i} -- [{tr[0]}, {tr[-1]}], [{tt[0]}, {tt[-1]}]\")\n",
    "    print(f\"Xtrain: {X[tr]}, Xtest: {X[tt]}\")\n",
    "n_splits = sum(1 for _ in rw.split(X))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_ = plot_cv_indices(rw, X, None, ax, n_splits)\n",
    "# ax.set_title('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rollwindow Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesRollWindowOLD:\n",
    "    \"\"\" Time Series Rolling Window cross-validator\n",
    "    \n",
    "        Provides train/test indices to split data samples\n",
    "        that are observed at fixed time intervals, in train/test sets.\n",
    "        In each split, test indices must be higher than before, \n",
    "        and thus shuffling in cross validator is inappropriate.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_size : int, required\n",
    "            Length of training set.\n",
    "\n",
    "        shift_step : int, required\n",
    "            Number of step to shift training window at each fold.\n",
    "            If equal to training_size the resulting test sets\n",
    "            do not overlap with training, if greater \n",
    "            \n",
    "        horizon: int, required\n",
    "            Length of test set(forecasting horizon)\n",
    "        \n",
    "        Return\n",
    "        -------\n",
    "        <genarator object> providing tuples of (Train, Test) indexes\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_size, shift_step, horizon):\n",
    "        self.train_size = train_size\n",
    "        self.shift_step = shift_step\n",
    "        self.horizon = horizon\n",
    "        self.n_splits = None\n",
    "\n",
    "    def get_n_splits(self, X, y=None, groups=None):\n",
    "\n",
    "        divider = (\n",
    "            self.train_size\n",
    "            if self.train_size >= self.shift_step\n",
    "            else self.shift_step - self.train_size\n",
    "        )\n",
    "        # set_trace()\n",
    "        if self.train_size != self.shift_step:\n",
    "            diff = self.train_size - self.shift_step\n",
    "        else:\n",
    "            diff = self.train_size\n",
    "        # sub = self.horizon if self.horizon >= self.shift_step else self.shift_step\n",
    "        # self.n_splits = ((len(X) - sub) // divider) + diff\n",
    "        available = len(X) - (self.train_size)\n",
    "        den = diff + self.horizon\n",
    "        print(f\"avail:{available}, den:{den}, diff:{diff}\")\n",
    "        self.n_splits = 1 + (available // diff)\n",
    "        print(f\"Inner count:{self.n_splits}\")\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        # define number of sample\n",
    "        n_samples = len(X)\n",
    "        # create an array of indexes\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        # defint initial start and end for training\n",
    "        startTrain = 0\n",
    "        startTest = 0\n",
    "        endTrain = self.train_size\n",
    "        endTest = 0\n",
    "\n",
    "        # set iteration condition i.e. iterate while\n",
    "        # trainig window + horizon does not reach the end\n",
    "        # of indexes array\n",
    "        # set_trace()\n",
    "        while (indices[-1] - endTest) >= 0:  # (endTrain + self.horizon)\n",
    "            startTest = endTrain\n",
    "            endTest = startTest + self.horizon\n",
    "            # define indexes for test set\n",
    "            indTest = indices[startTest:endTest]\n",
    "            # define training indexes\n",
    "            indTrain = indices[startTrain:endTrain]\n",
    "            # yield tuple of training and test indexes\n",
    "            yield indTrain, indTest\n",
    "            # update train indexes for next iteration\n",
    "            startTrain = startTrain + self.shift_step\n",
    "            endTrain = startTrain + self.train_size\n",
    "            # check condition before next iteration\n",
    "            if (indices[-1] - (endTrain + self.horizon)) < 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesRollWindow:\n",
    "    \"\"\" Time Series Rolling Window cross-validator\n",
    "    \n",
    "        Provides train/test indices to split data samples\n",
    "        that are observed at fixed time intervals, in train/test sets.\n",
    "        In each split, test indices must be higher than before, \n",
    "        and thus shuffling in cross validator is inappropriate.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_size : int, required\n",
    "            Length of training set.\n",
    "\n",
    "        shift_step : int, required\n",
    "            Number of step to shift training window at each fold.\n",
    "            If equal to training_size the resulting test sets\n",
    "            do not overlap with training, if greater \n",
    "            \n",
    "        horizon: int, required\n",
    "            Length of test set(forecasting horizon)\n",
    "        \n",
    "        Return\n",
    "        -------\n",
    "        <genarator object> providing tuples of (Train, Test) indexes\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_size, shift_step, horizon):\n",
    "        self.train_size = train_size\n",
    "        self.shift_step = shift_step\n",
    "        self.horizon = horizon\n",
    "        self.n_splits = None\n",
    "\n",
    "    def get_n_splits(self, X, y=None, groups=None):\n",
    "        n_samples=len(X)\n",
    "        a = np.arange(n_samples)\n",
    "        b = np.ones(self.train_size + self.horizon)\n",
    "        shift_b = np.ones(self.shift_step)\n",
    "        nsplit = 0\n",
    "        while len(b) < len(a):\n",
    "            b = np.append(b, shift_b)\n",
    "            nsplit += 1\n",
    "        self.n_splits = nsplit\n",
    "\n",
    "        if self.n_splits > n_samples:\n",
    "            raise ValueError(\n",
    "                (\n",
    "                    \"Cannot have number of splits/folds ={0} greater\"\n",
    "                    \" than the number of samples: {1}.\"\n",
    "                ).format(self.n_splits, n_samples)\n",
    "            )\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        # define number of sample\n",
    "        n_samples = len(X)\n",
    "        # create an array of indexes\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        # defint initial start and end for training\n",
    "        startTrain = 0\n",
    "        startTest = 0\n",
    "        endTrain = self.train_size\n",
    "        endTest = 0\n",
    "\n",
    "        # set iteration condition i.e. iterate while\n",
    "        # trainig window + horizon does not reach the end\n",
    "        # of indexes array\n",
    "        # set_trace()\n",
    "        while (indices[-1] - endTest) >= 0:  # (endTrain + self.horizon)\n",
    "            startTest = endTrain\n",
    "            endTest = startTest + self.horizon\n",
    "            # define indexes for test set\n",
    "            indTest = indices[startTest:endTest]\n",
    "            # define training indexes\n",
    "            indTrain = indices[startTrain:endTrain]\n",
    "            # yield tuple of training and test indexes\n",
    "            yield indTrain, indTest\n",
    "            # update train indexes for next iteration\n",
    "            startTrain = startTrain + self.shift_step\n",
    "            endTrain = startTrain + self.train_size\n",
    "            # check condition before next iteration\n",
    "            if (indices[-1] - (endTrain + self.horizon)) < 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train size:3, Period:4, Horizon:3\n",
      "\n",
      "\n",
      "Xtrain: [1 4 7], Xtest: [10 13 16]\n",
      "Xtrain: [13 16 19], Xtest: [22 25 28]\n",
      "Xtrain: [25 28 31], Xtest: [34 37 40]\n",
      "Xtrain: [37 40 43], Xtest: [46 49 52]\n",
      "Number of splits: 4\n",
      "Number splits returned by generator:4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEHCAYAAACk6V2yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAWnklEQVR4nO3deZhldX3n8feHHQaMBBpjgLZlBBIgBE3BCKJxQZS4EAVB1CgxI8NiHI1O3LeEjLZR4kwUARdAB9mCC5EhwsMi+1KNLAKyiI0wEGwEBIM20nznj3MKbt+urr7VVbe6+vT79Tz3qXt+59zf+d7bXZ/7O79z7q1UFZKk7llrVRcgSRoOA16SOsqAl6SOMuAlqaMMeEnqKANekjrKgO+YJDXA7cVJDm7vbzyDte2U5DtJ7k3y6yQ/TXJKkp2mqf8Xt89pWvrr6ffCntfu8SQLkxybZM501Nguv7O9//dJHk2ybt/jTm2327Ov/R1t+++3ywuTfHblnukytX42ycLp6EurxjqrugBNu9177m8InA8cCZzV034TcGO77aMzUVSS5wBXAFcB7wQeBLYF3gDsDPxoGnZzDc1z+sk09NXvAuBDNL8zz6N5Tf8zsNc07+cy4CPAc2leqzF70Pxb7QFc0te+sKruaZdfB/ximmvSasqA75iqumLsfs/o/Ce97T0WzUxVAPwlsBjYp6oWt23nA8cmyVQ6bh+/flU9TPMmMgwP9LyGlyTZCPhUkt/vCdfpcDlQNMF9FUCSrYCtgGPa9l57AJeOLVTVD6exFq3mnKJZQ/VP0SSZ1y6/McnxSR5OcneSt7Tr/zbJPUkWJZmfZK2+/nZKclaSR9rb6Ul+r2eTpwMP9YT7k6rv49RJ9k0ymuQ3Sf49yWd6pyySfCLJ/Un2THI18BvgDcuZ/lgryQeS3J5kcZJbk7ytb397Jrm4fc4PJ7k2yRtW8BJe1/7cuq+vlya5sq39viRHT2YarKoeojnC6g3yPYA7gO/Qc4SWZDNgO5pR/1jbUlM0SU5oX8uXJ7k+yX8kuSTJjn11Pz3JN9v19yb58Hj1JdklyXntNNKDSU5K8oye9RclOa5n+RXtv8lRPW37JXmsfZPUEBnw6jcfuBfYD7gYODHJ54DdgLcDnwf+Fjhg7AHt9MulwAbAXwAHAzsC/9ozOr8G2CbJ/0qyw/J2nuQA4Fs0o9fXAp8EDgE+1bfpRsCJwFeAV7L0dEavf6aZ8jgOeBXwbeBrSV7d7u9pwPdoAnQ/YH/gGzRvSBOZCzwB3NlT+w7AvwH3t319HHgT8C8r6KvfZSwd8LvTjOyvBOa0rzc921zKxOYC/wj8A3AQsAVwWt+R0/HAPsC7aV7vvYE39nbSnnO4kOa1fxPw18CfAucmWa/d7CLghT0PexHNG3B/2zVVNSPTg2u0qvLW0RuwMc3h/sHjrDu4XbdxuzyvXT6+Z5unAb8FbgPW7mm/Cji1Z/kbwC3Aej1t2wJLgFe1y+sAp7b7KJp54m8AIz2PCU1gHt9X69uBXwObtcufaPvYt2+7F7ftO7XLz6EJ4bf1bfd14Or2/kj7mE0meB0vBM5on8P6tPPewJf6tjtlnNfqgLb/3cersW0r4J3j/NvMbZevBI5o798IvLW9/yngYWCtnscuBD7bs3wC8DiwbU/bn7f9/0G7vGO7fGDf/50HaOb3x9o+DTwEPK2nbbf2sQe1y69ol+e0yxcBX2hrGPu/dg3wj6v692NNuDmCV7/zxu5UM6e9CPhBVS3p2eZ2YMue5b1oRsZPJFknyTrAT2nCZqTt6/GqOhD4Y+CjwAKa8Ls8yavafrajGW2eNtZP29f5NEcHvVfHFHD2Cp7Ly2gC/tt9/Z0H7JJkbZoTsr8CvtlODS1v5P56mje739CMmO8D3tW3zW7At/teqzNowm1PBjc2It8jyQY0J1wvb9uu4KmR+x7AFVX1xAr6W1hVt/Us39T+3Kr9uWv788yxDarqV8C5ff3sBpzT/r8Y2+4qmn/nsed3Gc0b+55J1m8f8xWao5rd2yOmnWmODjVkBrz6PdS3/Nhy2jboWd4ceD9NAPbetqFvjrqqrq+qI6tqb2B7mumgI3v6Afi/ff38tG3v7evBqnpsBc9lc2Bt4Jd9/Z1AMxp/ZlU9SDMdsS5wGrCoPZewTV9f59ME4Z4001i79dQ95pk0wd/7fJfQHK387gpq7X3MbTRvrHvQvEE+Blzfrr6cJvjXadetaHoGxv/3g6f+DX8PeKSqft233c/7lpd5fq37aJ9fVT0CXEszJbMbzZHX9TRX/rwQeAFN7gxSt6bIq2g0HR6gGcF/ZZx19y/vQVW1MMnpwOE9/UAzBzze1SA/7bk/yPdcP0Azen4BzUi+38/bOi4HXplkQ5qjkaOAbwLP79n2waoabe9f2s5HvzvJF6rqrrb9Xpr57Se1Rwmb9Ty3QV1OE/B300wnPd7TfizN3PdGTE9Q/juwSZIN+0J+i77tlnl+rWfQHJGNuZgmzH8BXFpVTyS5mGZqaF3gpqryUs4ZYMBrOpxHM32yoNpJ1n5Jtqiq/hEhNHP1Y6PCW4D/B8yrqi9PQ13n04zgf6eq+qcbltGG27+2V+F8cAWbfxx4C/Ae4G/atiuB1yX5UM80zetpfs8uWbaLCV1Kc1L0AZ6anoFmeuWRdp9L2n1O1dXtz9fSnCcZu8T25TRz/GOuBA5Lskk7UifJrjTnb3qf38U0J2AfA77btl1Ec87gP+H0zIwx4DUdPkFz4vWsJF+jGbVvSRMQJ1TVhcBHk/wxzcj4Zppf9NcDrwHeB9CO9N4LfKOdqz2bJiS2oRn97V+TuPKiqm5JcgxwSpLPAKM00xI7AttV1X9t5//fTnMJ4s/auv8bzZvDRH3fneRE4B1J/q6ayxuPpDny+E6SL9HMcc8Hvt8eJUzGZTS/n3vRXAk0tt9KciXNFS/XjQXtVFTVjUnOBL7Uvu73Av+DZT8EdxRwGPD9JPNpTsR+GriB5lzDmItp3lj3AN7btl1HMz22K82VWJoBzsFryqrqVprpjEdpLkc8m+byxsU0J2QBTqI5ofnedv3XgR1orr74XE9fpwL7ArsAp9NcMnk4zZUXK5pzH88RwN8Db6WZ2z+B5nLJi9r1t9NM9/xP4BzgMzSXOr59gL4/TfOGcVhb+400wbtFW/eRwMk0l15O1ijN8w3Lfnjr8rb9sv4HTcHBNM//88BXaY7KTundoKoWAS+hOdF8MvBFmjB/ee/5kHa7H9P8f1jQtj3RU+9kj2a0krKcI2pJ0mrOEbwkdZQBL0kdZcBLUkcZ8JLUUbPqMsnNN9+85s2bt6rLkKTVxoIFC+6vqnH/+MysCvh58+YxOjq64g0lSQAkuXN565yikaSOMuAlqaMMeEnqKANekjrKgJekjjLgJamjDHhJ6igDXpI6yoCXpI4y4CWpowx4SeooA16SOsqAl6SOMuAlqaMMeEnqKANekjrKgJekjjLgJamjDHhJ6igDXpI6yoCXpI4y4CWpowx4SeooA16SOsqAl6SOMuAlqaMMeEnqKANekjrKgJekjjLgJamjDHhJ6igDXpI6yoCXpI4y4CWpowx4SeooA16SOsqAl6SOWmdVFzAVh85/cNz2Y96/6Yz3M1213HX4fuO2b330Gat1P5JmniN4SeqooQZ8klcmuSXJ7Uk+MMx9SZKWNrSAT7I28EVgH2AH4KAkOwxrf5KkpQ1zBL8bcHtV3VFVjwGnAPsOcX+SpB7DDPgtgbt6lu9u25aS5JAko0lGFy1aNMRyJGnNMsyAzzhttUxD1XFVNVJVI3PmzBliOZK0ZhlmwN8NbN2zvBVwzxD3J0nqMcyAvxrYNsmzk6wHvBE4c4j7kyT1GNoHnarq8STvBL4PrA18rapuHNb+JElLS9Uy0+KrzMjISI2Ojq7qMiRptZFkQVWNjLfOT7JKUkcZ8JLUUQa8JHWUAS9JHWXAS1JHGfCS1FEGvCR1lAEvSR1lwEtSRxnwktRRBrwkdZQBL0kdZcBLUkcZ8JLUUQa8JHWUAS9JHWXAS1JHGfCS1FEGvCR1lAEvSR1lwEtSRxnwktRRBrwkdZQBL0kdZcBLUkcZ8JLUUQa8JHWUAS9JHWXAS1JHGfCS1FEGvCR11DqDbJRkS+BZvdtX1UXDKkqSNHUrDPgk84EDgZuAJW1zAQb8LHbo/AfHbT/m/Zuutv3cdfh+47ZvffQZk6pltvUjDcsgI/g/B7avqsXDLkaSNH0GmYO/A1h3sh0n+VqSnyf50eTLkiRN1SAj+EeBa5OcBzw5iq+qd63gcScAXwC+vtLVSZJW2iABf2Z7m5SquijJvMk+TpI0PVYY8FV1YpL1gO3apluq6rfTVUCSQ4BDAObOnTtd3UrSGm+Fc/BJXgzcBnwROBq4NcmLpquAqjquqkaqamTOnDnT1a0krfEGmaL5HLB3Vd0CkGQ74GTgT4ZZmCRpaga5imbdsXAHqKpbWYmraiRJM2uQgB9N8tUkL25vXwYWrOhBSU4GLge2T3J3kr+aarGSpMGlqibeIFkfOALYEwjNJ1iPHsYHn0ZGRmp0dHS6u5WkzkqyoKpGxls3yFU0i4Gj2pskaTWx3IBPclpVHZDkBprvnllKVe081MokSVMy0Qj+v7c/Xz0ThUiSptdyT7JW1b3t3cOr6s7eG3D4zJQnSVpZg1xF8/Jx2vaZ7kIkSdNrojn4w2hG6tskub5n1SbApcMuTJI0NRPNwX8TOBv4FPCBnvZHquqBoVYlSZqy5QZ8Vf0S+CVwEECSLYANgI2TbFxVP5uZEiVJK2OQLxt7TZLbgJ8CPwAW0ozsJUmz2CAnWY8Eng/cWlXPBl6Gc/CSNOsNEvC/rapfAGslWauqLgB2GXJdkqQpGuTrgh9KsjHNd9CclOTnwOPDLUuSNFWDjOD3pfm7rO8B/g34CfCaYRYlSZq6CUfwSdYGvltVewFPACfOSFWSpCmbcARfVUuAR5P8zgzVI0maJoPMwf8GuCHJucB/jDVW1buGVpUkacoGCfiz2pskaTUyyB/8ODHJhsDc3r/NKkma3Qb6JCtwLc0VNCTZJcmZwy5MkjQ1g1wm+QlgN+AhgKq6Fnj2EGuSJE2DQQL+8faLx3pN/Je6JUmr3CAnWX+U5E3A2km2Bd4FXDbcsiRJUzXICP6vgR2BxTTfEf9Lnvp7rZKkWWqQEfyrqurDwIfHGpK8ATh9aFVJkqZskBH8BwdskyTNIhP9TdZ9gD8Dtkzyv3tWPQ2/TVKSZr2JpmjuAUaB1wILetofoflmSUnSLDbR32S9DrguyUlV5YhdklYzE03RnFZVBwA/TLLMde9VtfNQK5MkTclEUzRjl0K+eiYKkSRNr4mmaO5tf945c+VIkqbLIJdJSpJWQwa8JHXURCdZ3wecWlV3zWA90tAdOv/BcduPef+mq20/dx2+37jtWx99xqRqmW39aGomGsFvCVyW5KIkhyXZfKaKkiRN3XIDvqreA8wFPgrsDFyf5Owkb02yyYo6TrJ1kguS3JzkxiR+QZkkzaAJ5+Cr8YOqOgzYGvg8zadY7xug78eB91bVHwLPB45IssNUC5YkDWaQb5MkyR8BbwQOBH4BfGhFj2kvsxy71PKRJDfTTPvctNLVSpIGNtFJ1m2Bg2iCfQlwCrB3Vd0x2Z0kmQc8F7hynHWHAIcAzJ07d7JdS5KWY6Ipmu8D6wMHVtUfVdU/rGS4bwycAby7qh7uX19Vx1XVSFWNzJkzZ7LdS5KWY6IpmlcAz6iqG3obk7wQuKeqfrKizpOsSxPuJ1XVt6ZUqSRpUiYawf8TsMyIG/g1zcnWCSUJ8FXg5qo6auXKkyStrIkCfl5VXd/fWFWjwLwB+n4B8BfAS5Nc297+bOXKlCRNVqqW+SbgZkVye1U9Z7LrpmJkZKRGR0enu1tJ6qwkC6pqZLx1E43gr07yjnE6+yuW/gtPkqRZaKKTrO8Gvp3kzTwV6CPAesDrhl2YJGlqJvo++PuAPZK8BNipbT6rqs6fkcokSVOywk+yVtUFwAUzUIskaRr5ffCS1FEGvCR1lAEvSR1lwEtSRxnwktRRBrwkdZQBL0kdZcBLUkcZ8JLUUQa8JHWUAS9JHWXAS1JHGfCS1FEGvCR1lAEvSR1lwEtSRxnwktRRBrwkdZQBL0kdZcBLUkcZ8JLUUQa8JHWUAS9JHWXAS1JHGfCS1FEGvCR1lAEvSR1lwEtSR62zqguQNHscOv/BcduPef+mq20/dx2+37jtWx99xqRqmW39DMIRvCR11NACPskGSa5Kcl2SG5N8clj7kiQta5hTNIuBl1bVr5KsC1yS5OyqumKI+5QktYYW8FVVwK/axXXbWw1rf5KkpQ11Dj7J2kmuBX4OnFtVV46zzSFJRpOMLlq0aJjlSNIaZagBX1VLqmoXYCtgtyQ7jbPNcVU1UlUjc+bMGWY5krRGmZGraKrqIeBC4JUzsT9J0nCvopmT5Ont/Q2BvYAfD2t/kqSlDfMqmmcCJyZZm+aN5LSq+t4Q9ydJ6pHmYpfZYWRkpEZHR1d1GZK02kiyoKpGxlvnJ1klqaMMeEnqKANekjrKgJekjjLgJamjDHhJ6igDXpI6yoCXpI4y4CWpowx4SeooA16SOsqAl6SOMuAlqaMMeEnqKANekjrKgJekjjLgJamjDHhJ6igDXpI6yoCXpI4y4CWpowx4SeooA16SOsqAl6SOMuAlqaMMeEnqKANekjrKgJekjjLgJamjDHhJ6igDXpI6yoCXpI4y4CWpowx4SeooA16SOsqAl6SOMuAlqaMMeEnqqFTVqq7hSUkWAXeu6jokaTXyrKqaM96KWRXwkqTp4xSNJHWUAS9JHWXAS1JHGfCa9ZJ8OMmNSa5Pcm2S/zLk/V2YZGQS2/9dkr0muY+FSTaffHXS4NZZ1QVIE0myO/Bq4HlVtbgNxfVWcVlLqaqPreoapPE4gtds90zg/qpaDFBV91fVPQBJPpbk6iQ/SnJckrTtFyb5pyQXJbk5ya5JvpXktiRHttvMS/LjJCe2Rwb/kmSj/p0n2TvJ5UmuSXJ6ko3H2eaEJPu39xcm+WS7/Q1J/qBt3yzJOUl+mORYID2Pf0uSq9qjk2OTrJ3kWW29mydZK8nFSfae/pdXXWbAa7Y7B9g6ya1Jjk7ypz3rvlBVu1bVTsCGNCP9MY9V1YuAY4DvAkcAOwEHJ9ms3WZ74Liq2hl4GDi8d8ft0cJHgL2q6nnAKPA3A9R8f7v9l4D3tW0fBy6pqucCZwJz2338IXAg8IKq2gVYAry5qu4E5rf1vxe4qarOGWDf0pMMeM1qVfUr4E+AQ4BFwKlJDm5XvyTJlUluAF4K7Njz0DPbnzcAN1bVve1RwB3A1u26u6rq0vb+/wH27Nv984EdgEuTXAu8DXjWAGV/q/25AJjX3n9Ruw+q6izgwbb9Ze3zu7rdx8uAbdrtvgJsAhzKU28U0sCcg9esV1VLgAuBC9swf1uSU4CjgZGquivJJ4ANeh62uP35RM/9seWx//f9n/LrXw5wblUdNMmSx/a3hKV/x8b7VGGAE6vqg8usaKaMtmoXNwYemWQdWsM5gteslmT7JNv2NO1C83UWY2F+fzsvvv9KdD+3PYkLcBBwSd/6K4AXJHlOW8tGSbZbif0AXAS8ue1nH2DTtv08YP8kW7TrfjfJ2FHCfOAk4GPAl1dyv1qDOYLXbLcx8M9Jng48DtwOHFJVDyX5Ms0UzELg6pXo+2aao4Fjgdto5syfVFWL2umgk5Os3zZ/BLh1Jfb1ybafa4AfAD9r93FTko8A5yRZC/gtcESSecCuNHPzS5Lsl+Qvq+r4ldi31lB+F43WSG2Afq89QSt1klM0ktRRjuAlqaMcwUtSRxnwktRRBrwkdZQBL0kdZcBLUkf9f35jUlg45bbjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_size_ts, step_ts, horizon_ts = 3, 4, 3\n",
    "rw = TimeSeriesRollWindow(\n",
    "    train_size=train_size_ts, shift_step=step_ts, horizon=horizon_ts\n",
    ")\n",
    "print(f\"\\nTrain size:{train_size_ts}, Period:{step_ts}, Horizon:{horizon_ts}\\n\\n\")\n",
    "for i, (tr, tt) in enumerate(rw.split(X)):\n",
    "    print(f\"Xtrain: {X[tr]}, Xtest: {X[tt]}\")\n",
    "    \n",
    "print(f'Number of splits: {rw.get_n_splits(X)}')\n",
    "# iterate generator to count number splits\n",
    "\n",
    "n_splits = sum(1 for _ in rw.split(X))\n",
    "print(f'Number splits returned by generator:{n_splits}')\n",
    "fig, ax = plt.subplots()\n",
    "_ = plot_cv_indices(rw, X, None, ax, n_splits)\n",
    "# ax.set_title('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(len(X))\n",
    "b = np.ones(train_size_ts + horizon_ts)\n",
    "shift_b = np.ones(step_ts)\n",
    "iterr = 0\n",
    "while len(b) < len(a):\n",
    "    # print(b)\n",
    "    b = np.append(b, shift_b)\n",
    "    iterr += 1\n",
    "print(iterr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeSeries Split implemented in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TimeSeriesSplit(n_splits=10)  # , max_train_size=4)\n",
    "n_splits = sum(1 for _ in ts.split(X))\n",
    "for i, (tr, tt) in enumerate(ts.split(X)):\n",
    "    print(f\"Iteration: {i} -- [{tr[0]}, {tr[-1]}], [{tt[0]}, {tt[-1]}]\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_ = plot_cv_indices(ts, X, None, ax, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Cross-Validation walk forward (Medium)\n",
    "[Time Series Cross-validation — a walk forward approach in python](https://medium.com/eatpredlove/time-series-cross-validation-a-walk-forward-approach-in-python-8534dd1db51a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class expanding_window(object):\n",
    "    \"\"\"\t\n",
    "    Parameters \n",
    "    ----------\n",
    "    \n",
    "    Note that if you define a horizon that is too far, \n",
    "    then subsequently the split will ignore horizon length \n",
    "    such that there is validation data left. \n",
    "    This similar to Prof Rob hyndman's TsCv \n",
    "    \n",
    "    \n",
    "    initial: int\n",
    "        initial train length \n",
    "    horizon: int \n",
    "        forecast horizon (forecast length). Default = 1\n",
    "    period: int \n",
    "        length of train data to add each iteration \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, initial=1, horizon=1, period=1):\n",
    "        self.initial = initial\n",
    "        self.horizon = horizon\n",
    "        self.period = period\n",
    "\n",
    "    def split(self, data):\n",
    "        \"\"\"\n",
    "        Parameters \n",
    "        ----------\n",
    "        \n",
    "        Data: Training data \n",
    "        \n",
    "        Returns \n",
    "        -------\n",
    "        train_index ,test_index: \n",
    "            index for train and valid set similar to sklearn model selection\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.counter = 0  # for us to iterate and track later\n",
    "\n",
    "        data_length = data.shape[0]  # rows\n",
    "        data_index = list(np.arange(data_length))\n",
    "\n",
    "        output_train = []\n",
    "        output_test = []\n",
    "        # append initial\n",
    "        output_train.append(list(np.arange(self.initial)))\n",
    "        progress = [\n",
    "            x for x in data_index if x not in list(np.arange(self.initial))\n",
    "        ]  # indexes left to append to train\n",
    "        output_test.append(\n",
    "            [x for x in data_index if x not in output_train[self.counter]][\n",
    "                : self.horizon\n",
    "            ]\n",
    "        )\n",
    "        # clip initial indexes from progress since that is what we are left\n",
    "\n",
    "        while len(progress) != 0:\n",
    "            temp = progress[: self.period]\n",
    "            to_add = output_train[self.counter] + temp\n",
    "            # update the train index\n",
    "            output_train.append(to_add)\n",
    "            # increment counter\n",
    "            self.counter += 1\n",
    "            # then we update the test index\n",
    "\n",
    "            to_add_test = [\n",
    "                x for x in data_index if x not in output_train[self.counter]\n",
    "            ][: self.horizon]\n",
    "            output_test.append(to_add_test)\n",
    "\n",
    "            # update progress\n",
    "            progress = [x for x in data_index if x not in output_train[self.counter]]\n",
    "\n",
    "        # clip the last element of output_train and output_test\n",
    "        output_train = output_train[:-1]\n",
    "        output_test = output_test[:-1]\n",
    "\n",
    "        # mimic sklearn output\n",
    "        index_output = [(train, test) for train, test in zip(output_train, output_test)]\n",
    "\n",
    "        return index_output\n",
    "\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "X\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "tscv = expanding_window(initial=2, horizon=2, period=1)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    print(f\"Train indexes:{train_index}, Test indexes:{test_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneStep TimeSeries CV\n",
    "From \"Hands-On Machine Learning for Algorithmic Trading\" (chapter 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStepTimeSeriesSplit:\n",
    "    \"\"\"Generates tuples of train_idx, test_idx pairs\n",
    "    Assumes the index contains a level labeled 'date'\"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=3, test_period_length=1, shuffle=False):\n",
    "        self.n_splits = n_splits\n",
    "        self.test_period_length = test_period_length\n",
    "        self.shuffle = shuffle\n",
    "        self.test_end = n_splits * test_period_length\n",
    "\n",
    "    @staticmethod\n",
    "    def chunks(l, chunk_size):\n",
    "        for i in range(0, len(l), chunk_size):\n",
    "            yield l[i : i + chunk_size]\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        unique_dates = (\n",
    "            X.index.get_level_values(\"date\")\n",
    "            .unique()\n",
    "            .sort_values(ascending=False)[: self.test_end]\n",
    "        )\n",
    "\n",
    "        dates = X.reset_index()[[\"date\"]]\n",
    "        for test_date in self.chunks(unique_dates, self.test_period_length):\n",
    "            train_idx = dates[dates.date < min(test_date)].index\n",
    "            test_idx = dates[dates.date.isin(test_date)].index\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(list(train_idx))\n",
    "            yield train_idx, test_idx\n",
    "\n",
    "    def get_n_splits(self, X, y, groups=None):\n",
    "        return self.n_splits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
